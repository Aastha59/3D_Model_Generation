# -*- coding: utf-8 -*-
"""#D_Model_Generation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13n6tJWSWfUG0W2Go7ZQTjCjA9aLVogIk
"""

# @title Step 1: PROPER Installation (Run This First!)
!pip install -q git+https://github.com/openai/shap-e.git
!pip install -q torch numpy

# @title Step 2: Verify Installation
import torch
from shap_e.models.download import load_model
print("✅ All dependencies working!")

# @title Step 1: Install Shap-E (Run First!)
!pip install -q git+https://github.com/openai/shap-e.git
!pip install -q torch numpy

# @title Step 1: INSTALL ALL DEPENDENCIES (Run First!)
!pip install -q git+https://github.com/openai/shap-e.git
!pip install -q torch numpy trimesh
!pip install -q pygltflib==1.1.0  # Specific stable version

# @title Step 1: INSTALL DEPENDENCIES (Run First!)
!pip uninstall shap-e -y
!pip install -q torch numpy
!pip install -q git+https://github.com/openai/shap-e.git
!pip install -q trimesh

# @title Step 2: COMPLETE WORKING GENERATOR
import torch
import os
from google.colab import files
from shap_e.models.download import load_model, load_config
from shap_e.diffusion.gaussian_diffusion import diffusion_from_config
from shap_e.diffusion.sample import sample_latents
from shap_e.util.notebooks import decode_latent_mesh
import trimesh

# Config
prompt = "a fantasy sword"  # @param {type:"string"}
output_dir = "outputs"
os.makedirs(output_dir, exist_ok=True)

# Load models
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Load components
xm = load_model('transmitter', device=device)
model = load_model('text300M', device=device)
diffusion = diffusion_from_config(load_config('diffusion'))

# Generate with ALL required parameters
print(f"Creating 3D model for: '{prompt}'...")
latents = sample_latents(
    batch_size=1,
    model=model,
    diffusion=diffusion,
    guidance_scale=10.0,
    model_kwargs=dict(texts=[prompt]),
    progress=True,
    clip_denoised=True,
    use_fp16=True if device.type == 'cuda' else False,
    use_karras=True,
    karras_steps=32,
    sigma_min=0.002,
    sigma_max=80.0,
    s_churn=3.0,
)

# Convert to mesh and export
mesh = decode_latent_mesh(xm, latents[0]).tri_mesh()
filename = prompt.replace(" ", "_")[:20] + ".glb"

# FIXED: Remove .cpu() since vertices/faces are already numpy arrays
trimesh.Trimesh(
    vertices=mesh.verts,  # Already numpy array
    faces=mesh.faces      # Already numpy array
).export(filename)

# Download
files.download(filename)
print(f"✅ Done! Downloaded: {filename}")

